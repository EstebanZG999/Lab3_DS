{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c68954b",
   "metadata": {},
   "source": [
    "# Modelos de Deep Learning\n",
    "\n",
    "Laboratorio 03 – Deep Learning\n",
    "\n",
    "Edwin Ortega 22305 - Esteban Zambrano 22119 - Diego García 22404\n",
    "\n",
    "Link del repositorio:<br>\n",
    "https://github.com/EstebanZG999/Lab3_DS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0925fa9e",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62ac79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b042f",
   "metadata": {},
   "source": [
    "### Verifica entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e6b897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿CUDA disponible?: True\n",
      "GPU detectada: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Verifica CUDA disponible\n",
    "print(\"¿CUDA disponible?:\", torch.cuda.is_available())\n",
    "\n",
    "# Verifica GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU detectada:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4f7ed",
   "metadata": {},
   "source": [
    "### Preprocesamiento y Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a968f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyMNISTDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Dataset personalizado para PolyMNIST.\n",
    "        - root_dir: carpeta raíz que contiene subcarpetas m0, m1, ..., m4.\n",
    "        - transform: transformaciones a aplicar a cada imagen.\n",
    "        \"\"\"\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for label in range(5):  # m0 = 0, m1 = 1, ..., m4 = 4\n",
    "            class_dir = os.path.join(root_dir, f\"m{label}\")\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.endswith(\".png\"):\n",
    "                    self.image_paths.append(os.path.join(class_dir, img_name))\n",
    "                    self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"L\")  # convertir a escala de grises\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0fc743",
   "metadata": {},
   "source": [
    "Cargar el dataset y crear el DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca56382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape batch imágenes: torch.Size([64, 1, 28, 28])\n",
      "Labels: tensor([3, 4, 3, 4, 3, 0, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Definir transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),       # Asegura tamaño uniforme\n",
    "    transforms.ToTensor(),             # Convierte a tensor (C, H, W)\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normaliza a [-1, 1]\n",
    "])\n",
    "\n",
    "# Dataset y DataLoader\n",
    "train_dir = \"../data/PolyMNIST/MMNIST/train\"\n",
    "train_dataset = PolyMNISTDataset(root_dir=train_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Verifica que funciona\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Shape batch imágenes: {images.shape}\")  # Esperado: (64, 1, 28, 28)\n",
    "print(f\"Labels: {labels[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d185130",
   "metadata": {},
   "source": [
    "GPU Check en el loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90b41fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando en: cuda\n",
      "Datos en GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# GPU Check en el loader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Entrenando en:\", device)\n",
    "\n",
    "# Mover un batch de prueba a GPU\n",
    "images, labels = next(iter(train_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "print(\"Datos en GPU:\", images.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afc5df7",
   "metadata": {},
   "source": [
    "### Primer Modelo - CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6efd6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Reducción de tamaño a la mitad\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)  # Flatten final\n",
    "        self.fc2 = nn.Linear(128, 5)  # 5 clases: m0 a m4\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # [1, 28, 28] -> [16, 14, 14]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # [16, 14, 14] -> [32, 7, 7]\n",
    "        x = x.view(-1, 32 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2702e105",
   "metadata": {},
   "source": [
    "##### Entrenaiento primer modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335ae0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de pérdida y optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "epochs = 5\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc  = correct / total\n",
    "    print(f\"Época {epoch}/{epochs} — Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "# Evaluación en el set de test\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_loss /= total\n",
    "test_acc  = correct / total\n",
    "print(f\"\\n— Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Guarda el modelo entrenado\n",
    "torch.save(model.state_dict(), \"cnn_polymnist_m0-4.pth\")\n",
    "print(\"\\nModelo guardado como cnn_polymnist_m0-4.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
